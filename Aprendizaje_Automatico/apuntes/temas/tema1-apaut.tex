%28/01 - Aythami Morales 
\chapter{Introducci칩n}
\section{Repaso: 츼lgebra lineal}
\subsection{Notaci칩n general}
Se denota un \textbf{vector} $\vec{x}$ como $x \in \mathbb{R}^n$ con $n$ entradas, donde $x_i \in \mathbb{R}$ es la entrada i-칠sima. Un vector se puede ver como una matriz de dimensiones $n \times 1$ y se denomina tambi칠n como vector-columna.
$$\vec{x} = \begin{pmatrix}
x_1 \\ x_2 \\ ... \\ x_n
\end{pmatrix} \in \mathbb{R}^n$$

Se denota una \textbf{matriz} $\vec{A}$ como $A \in \mathbb{R}^{m \times n}$ con n columnas y m filas, donde $A_{i,j} \in \mathbb{R}$ es la entrada en la fila i-칠sima y columna j-칠sima.
$$\vec{A} = \begin{pmatrix}
A_{1,1} & ... & A_{1,n} \\
... & & ...\\
A_{m,1} & ... & A_{m,n}
\end{pmatrix} \in \mathbb{R}^{m \times n}$$

Una \textbf{matriz de identidad} $\vec{I} \in \mathbb{R}^{n \times n}$ es una matriz cuadrada con 1 en la diagonal principal y 0 en el resto. Para cualquier matriz $\vec{A} \in \mathbb{R}^{n \times n}$, se cumple que $\vec{A} \times \vec{I} = \vec{I} \times \vec{A} = \vec{A}$.
$$\vec{I} = \begin{pmatrix}
1 & 0 & ... & 0 \\
0 & 1 & ... & ... \\
... & ... & 1 & 0 \\
0 & ... & 0 & 1
\end{pmatrix}$$

\subsection{Operaciones de matrices}
\paragraph{Multiplicaci칩n vector-vector}
Hay dos tipos de productos vector-vector:
\begin{itemize}
\item \textbf{Producto interno (inner product):}
Dados dos vectores $\vec{x},\vec{y} \in \mathbb{R}^n$ de la misma dimensi칩n, el producto interno es un escalar (un s칩lo n칰mero). Se usa en c치lculos que involucran proyecciones, determinaci칩n de ortogonalidad, etc. El producto interno puede aplicarse en cualquier dimensi칩n.
$$\vec{x}^T y = \sum^n_{i=1} x_iy_i \in \mathbb{R} $$

\item \textbf{Producto externo (outer product):}
Dados dos vectores, no necesariamente de la misma dimensi칩n, $\vec{x} \in \mathbb{R}^m, \vec{y} \in \mathbb{R}^n$, el producto externo es una matriz de $m \times n$.
$$xy^T = \begin{pmatrix}
x_1 y_1 & ... & x_1 y_n \\
...  & & ... \\
x_m y_1 & ... & x_m y_n
\end{pmatrix} \in \mathbb{R}^{m \times n}$$

El producto externo tiene como aplicaciones para la bioinform치tica:
\subsubsection{츼lgebra Lineal}
\textbf{Matrices de Covarianza}: Se utiliza en la construcci칩n de matrices de covarianza, que son fundamentales en estad칤stica y an치lisis de datos.
\textbf{Representaci칩n de Transformaciones}: Ayuda a representar transformaciones lineales y rotaciones en el espacio.
\subsubsection{An치lisis de Datos y Machine Learning}
\textbf{Modelos de Regresi칩n}: En algunos m칠todos de regresi칩n, como la regresi칩n de m칤nimos cuadrados, se utiliza el producto externo para construir matrices de dise침o.
\textbf{M칠todos de Factorizaci칩n}: Se aplica en t칠cnicas como la factorizaci칩n de matrices y la descomposici칩n en valores singulares (SVD), que son esenciales en la reducci칩n de dimensionalidad y an치lisis de componentes principales (PCA).
\end{itemize}

\paragraph{Multiplicaci칩n matriz-vector} Dada una matriz $\vec{A} \in \mathbb{R}^{m \times n}$ y un vector $\vec{x} \in \mathbb{R}^n$, el producto es un vector del tama침o $\mathbb{R}^m$. El proceso consiste en multiplicar cada fila de la matriz $洧냢$ por el vector $洧논$ y sumar los resultados.
$$Ax = \begin{pmatrix}
A_{1,1}x_1 + A_{1,2}x_2 + ... + A_{1,n}x_n \\
... \\
A_{m,1}x_1 + A_{m,2}x_2 + ... + A_{m,n}x_n
\end{pmatrix} \in \mathbb{R}^m$$

\begin{figure}[h]
\centering
\includegraphics[width = 0.5\textwidth]{figs/matrix-vector-mult.png}
\end{figure}

\subsection{Aplicaciones del Producto Externo}
\subsubsection{츼lgebra Lineal}
\textbf{Matrices de Covarianza}: Se utiliza en la construcci칩n de matrices de covarianza, que son fundamentales en estad칤stica y an치lisis de datos.
\textbf{Representaci칩n de Transformaciones}: Ayuda a representar transformaciones lineales y rotaciones en el espacio.
\subsubsection{An치lisis de Datos y Machine Learning}
\textbf{Modelos de Regresi칩n}: En algunos m칠todos de regresi칩n, como la regresi칩n de m칤nimos cuadrados, se utiliza el producto externo para construir matrices de dise침o.
\textbf{M칠todos de Factorizaci칩n}: Se aplica en t칠cnicas como la factorizaci칩n de matrices y la descomposici칩n en valores singulares (SVD), que son esenciales en la reducci칩n de dimensionalidad y an치lisis de componentes principales (PCA).

\paragraph{Multiplicaci칩n matriz-matriz} Dadas dos matrices $\vec{A} \in \mathbb{R}^{m \times n}$ y $\vec{B} \in \mathbb{R}^{n \times p}$, el producto es una matriz de tama침o $\mathbb{R}^{m \times p}$.
$$\vec{AB} = \begin{pmatrix}
\sum^n_{k=1}A_{1,k}B_{k,1} & ... & \sum^n_{k=1}A_{1,k}B_{k,p} \\
... & ... & ...\\
\sum^n_{k=1}A_{m,1}B_{k,1} & ... & \sum^n_{k=1}A_{m,k}B_{k,p}
\end{pmatrix} \in \mathbb{R}^{m \times p}$$

\begin{figure}[h]
\centering
\includegraphics[width = 0.7\textwidth]{figs/matrix-matrix-mult.png}
\end{figure}

\subsection{Aplicaciones de la Multiplicaci칩n Matriz-Vector}
\subsubsection{츼lgebra Lineal y Matem치ticas Puras}
\textbf{Sistemas de Ecuaciones Lineales}: Resolver sistemas de ecuaciones de la forma \(Ax = b\).
\textbf{Transformaciones Lineales}: Representar y aplicar transformaciones lineales como rotaciones, escalamientos y reflexiones.

\subsubsection{Computaci칩n y Algoritmos}
\textbf{Algoritmos de Optimizaci칩n}: Implementar m칠todos de optimizaci칩n como gradiente descendente.
\textbf{An치lisis de Gr치ficos}: Procesar datos en grafos y redes, como algoritmos de PageRank.
\textbf{Compresi칩n de Datos}: Utilizar en algoritmos de compresi칩n de datos y an치lisis de componentes principales (PCA).

\subsubsection{Machine Learning e Inteligencia Artificial}
\textbf{Regresi칩n Lineal}: Resolver problemas de regresi칩n lineal para ajustar modelos a datos.
\textbf{Redes Neuronales}: Calcular activaciones y actualizar pesos en redes neuronales.

\subsubsection{Bioinform치tica}
\textbf{An치lisis de Datos Gen칩micos}: Procesar y analizar grandes vol칰menes de datos gen칩micos y de secuenciaci칩n.

\subsection{Propiedades de la multiplicaci칩n de matrices}
\paragraph{No conmutatividad:} En general, la multiplicaci칩n de matrices no es conmutativa, es decir, $\vec{A} \times \vec{B} \neq \vec{B} \times \vec{A}$. Por ejemplo:
$$\begin{bmatrix}
1 & 1 \\ 0 & 0
\end{bmatrix} \times \begin{bmatrix}
0 & 0 \\ 2 & 0
\end{bmatrix} = \begin{bmatrix}
2 & 0 \\ 0 & 0
\end{bmatrix} $$

$$\begin{bmatrix}
0 & 0 \\ 2 & 0
\end{bmatrix} \times \begin{bmatrix}
1 & 1 \\ 0 & 0
\end{bmatrix} = \begin{bmatrix}
0 & 0 \\ 2 & 2
\end{bmatrix} $$

En el caso de multiplicar una matriz con una matriz de identidad, s칤 es conmutativa.

\paragraph{Matriz inversa} Si $\vec{A}$ es una matriz cuadrada $m \times m$, y tiene inversa, entonces
$$AA^{-1} = A^{-1}A = I$$

\paragraph{Transposici칩n de matriz} Dada una matriz $A \in \mathbb{R}^{m \times n}$, su transpuesta $A^T$: es una matriz $n \times m$ donde $\forall i, j, \quad (A^T)_{ij} = A_{ji}$. Por ejemplo:
\begin{table}[h]
\centering
$A = \begin{bmatrix}
1 & 2 & 0 \\ 3 & 5 & 9
\end{bmatrix}$
\qquad \qquad \qquad
$A^T = \begin{bmatrix}
1 & 3 \\ 2 & 5 \\ 0 & 9
\end{bmatrix} $
\end{table}
% Luis -> meter el resto de operaciones y propiedades de https://stanford.edu/~shervine/teaching/cs-229/refresher-algebra-calculus (el finde quiz치?).

\section{Introducci칩n al Aprendizaje Autom치tico o Machine Learning}
\subsection{Contexto hist칩rico}
Hay muchas definiciones de aprendizaje autom치tico. Seg칰n Wikipedia, machine learning es la construcci칩n y estudio de sistemas que pueden aprender de datos. Arthur Samuel lo defin칤a como un campo de estudio que confiere a los ordenadores la capacidad de aprender sin ser programados expl칤citamente. En el aprendizaje autom치tico, no se dise침a el algoritmo para que resuelva una tarea con unas reglas fijas, si no para que con una serie de datos pueda aprender a resolver la tarea. 

Arthur Samuel, en la d칠cada de 1950, escribi칩 un programa para jugar a las damas que era capaz de aprender las mejores posiciones del tablero analizando miles de partidas. El sistema aprendi칩 por s칤 mismo a jugar a las damas cada vez mejor. El 11 de mayo de 1997, el gran maestro de ajedrez Garry Kasparov renuncia tras 19 movimientos en una partida contra Deep Blue, un ordenador ajedrecista desarrollado por cient칤ficos de IBM. En 2016, Google (AlphaGo) derrot칩 al campe칩n mundial de Go. Este juego fue considerado durante d칠cadas uno de los grandes retos de la IA. \footnote{Para el ajedrez, no se trata realmente de una inteligencia artificial, si no una m치quina que calcula probabilidades. Cada movimiento proporciona una probabilidad de vencer al contrincante. Hay aperturas del ajedrez que facilitan un poco la victoria. Esto para el Go no existe. La m치quina pudo encontrar una t치ctica para el Go nunca antes descrita, abriendo el debate de si se trata de creatividad.} En 2020, Google (AlphaFold) predice la estructura de las prote칤nas. Aqu칤 se basa de \textbf{aprendizaje por refuerzo}. Se utiliz칩 AlphaGo como base para generar otros modelos similares: AlphaChess, AlphaFold, etc. Las damas, el ajedrez, el go y las estructuras de las prote칤nas tienen en com칰n ser problemas con unas reglas bien definidas. A partir de reglas sencillas, se generan estructuras complejas. Por ello, son campos donde se puede predecir o estimar muchas combinaciones y posibles variaciones. Estos algoritmos funcionan por prueba y error, por lo que no tiene sentido aplicarlo en otros campos donde los errores tienen consecuencias graves, como puede ser el diagn칩stico de enfermedades o la conducci칩n aut칩noma de coches. En general, todo el comportamiento humano es imposible de describir en reglas; cada paciente es muy complejo en s칤 mismo, siendo dif칤cil generalizar en poblaciones grandes por procesos moleculares, comportamiento, epigen칠tica, etc. 

La IA se ha democratizado mucho con los softwares open-source. Tecnol칩gicamente no hay secretos a d칤a de hoy, solo diferencias en los datos y el hardware. 

\subsection{De programaci칩n cl치sica al aprendizaje autom치tico}
Los humanos adquieren con el tiempo experiencias que les hace aprender, causando respuestas concretas a distintas situaciones. Los ordenadores y las m치quinas obtienen reglas predefinidas y datos, y con programaci칩n cl치sica llegan a su respuesta. No obstante, actualmente se utilizan datos y respuestas para, mediante aprendizaje autom치tico, poder inferir las reglas. Esto invierte la forma de funcionar los ordenadores, y ha sido lo revolucionario del campo. Esas reglas inferidas se utilizar치n para nuevos datos y poder ser cada vez m치s precisas. As칤, el algoritmo encuentra las mejores reglas para resolver un problema. Estas reglas son ecuaciones matem치ticas, pudiendo ser propensas a sesgos en base a los datos.

\subsection{De comportamiento humano a comportamiento computacional: el modelo est치ndar}
Una tarea humana se realiza a trav칠s de unos objetivos mediante abstracci칩n. El proceso de aprendizaje est치 guiado por objetivos predefinidos (es decir, la simplificaci칩n de comportamientos complejos). En el caso de las m치quinas,  el proceso de aprendizaje consta de etapas de optimizaci칩n para llegar al objetivo. Al final se trata de una reducci칩n y optimizaci칩n de la abstracci칩n humana. No obstante, no hay una visi칩n directa entre el comportamiento de la m치quina y el comportamiento humano. No se puede esperar que un algoritmo sea justo o generoso por naturaleza si no se especifica en sus objetivos. Por ello, es muy f치cil que aparezcan sesgos en el aprendizaje autom치tico. La toma de decisi칩n es muy diferente entre un humano y una m치quina.

\subsection{C칩mo ve la IA: Un ejemplo con ataques adversarios}
Tenemos una imagen de un cerdo (figura \ref{fig:pig}), y no necesitamos el ruido para saber lo que es. Si le a침adimos ruido a la imagen, aunque sea en una baja cantidad, la imagen no cambia para los humanos. No obstante, el sistema de reconocimiento de im치genes lo reconoce como una aerol칤nea. El ruido no es aleatorio, si no adversario. Esto quiere decir que la entrada al modelo ha sido modificada ligeramente de forma intencional, haciendo que el modelo genere una salida incorrecta. Se manipula para confundir a la m치quina.

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.9\textwidth]{figs/pig-ai.png}
\caption{Reconocimiento de im치genes con ataque adversario.}
\label{fig:pig}
\end{figure}

\subsection{Cognici칩n humana: sistema 1 vs sistema 2}
Los conceptos del libro Thinking, Fast and Slow de Daniel Kahneman se han aplicado en el campo del aprendizaje autom치tico. Se habla de dos sistemas y categor칤as de tareas cognitivas. El \textbf{sistema 1} es intuitivo, r치pido, inconsciente, no ling칲칤stico y habitual. Se dec칤a que el aprendizaje profundo estaba en ese sistema. El \textbf{sistema 2} es lento, l칩gico, secuencial, consciente, ling칲칤stico, algor칤tmico, y es donde estar칤a el deep learning futuro. Esto sirvi칩 para el aprendizaje autom치tico de estructuras de datos: redes de c치psulas, aprendizaje autom치tico neurosint치ctico, razonamiento conceptual, bases de experiencia, reglas l칩gicas, etc. \textit{El sistema 1 sirve para reconocer formas, colores y posiciones, mientras que el sistema 2 ayuda en la predicci칩n de interacciones.}

\subsection{Tarea de aprendizaje}
Se dice que un programa inform치tico aprende de la experiencia E con respecto a alguna tarea T y alguna medida de rendimiento P, si su rendimiento en T, medido por P, mejora con la experiencia E. Si el rendimiento es perfecto desde el principio, no hay aprendizaje, ya que requiere una optimizaci칩n o mejora del estado. Ejemplos son:
\begin{itemize}
\item T: Jugar a las damas \\ P: Porcentaje de partidas ganadas contra un contrincante arbitrario \\ E: Jugar partidas de pr치ctica contra uno mismo
\item T: Reconocer palabras escritas a mano \\ P: Porcentaje de palabras clasificadas correctamente \\ E: Base de datos de im치genes de palabras manuscritas etiquetadas por humanos
\item T: Conducci칩n en autopistas de cuatro carriles mediante sensores de visi칩n \\ P: Distancia media recorrida antes de un error apreciado por el ser humano \\ E: Secuencia de im치genes y comandos de direcci칩n grabados mientras se observa a un conductor humano.
\item T: clasificar los mensajes de correo electr칩nico como spam o leg칤timos. \\ P: Porcentaje de mensajes de correo electr칩nico clasificados correctamente. \\ E: Base de datos de correos electr칩nicos, algunos con etiquetas dadas por humanos.
\end{itemize}

\subsection{Aprendizaje autom치tico en contexto}
En el n칰cleo de la IA, el aprendizaje autom치tico es simplemente una forma de conseguir IA. En lugar de codificar rutinas de software con instrucciones espec칤ficas para realizar una tarea concreta, el ML es una forma de 춺entrenar췉 un algoritmo para que aprenda a hacerlo. El 춺entrenamiento췉 consiste en introducir grandes cantidades de datos en el algoritmo y permitir que 칠ste se ajuste y mejore.

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.8\textwidth]{figs/ai-timeline.png}
\caption{Mapa temporal del desarrollo de las inteligencias artificiales. Ya est치 algo desfasado, faltar칤a a침adir despu칠s del Deep Learning los Modelos Generativos.}
\end{figure}

No se trata de comparar el aprendizaje humano vs aprendizaje autom치tico, si no combinar ambos para sacar lo mejor de los dos mundos. Habr치 tareas que se ir치n automatizando.

\subsection{Dise침o de sistema de aprendizaje}
Muchos m칠todos de aprendizaje implican formaci칩n. La formaci칩n es la adquisici칩n de conocimientos, destrezas y competencias como resultado de la ense침anza de aptitudes o conocimientos pr치cticos relacionados con una competencia 칰til. La formaci칩n requiere escenarios o ejemplos (datos). Existen varios tipos de sistemas de aprendizaje:
\begin{itemize}
\item \textbf{Aprendizaje no supervisado:} No se proporcionan respuestas o retroalimentaci칩n expl칤cita. El sistema debe encontrar patrones o estructuras en los datos por s칤 mismo.
\item \textbf{Aprendizaje supervisado:} Se utiliza un conjunto de datos etiquetados, es decir, se proporcionan ejemplos con las respuestas correctas. El sistema aprende a mapear las entradas (x) a las salidas (y) bas치ndose en estos ejemplos.
\item \textbf{Aprendizaje de refuerzo:} La retroalimentaci칩n es indirecta y se recibe despu칠s de varias acciones o decisiones. El sistema aprende a trav칠s de la interacci칩n con un entorno, recibiendo recompensas o penalizaciones.
\end{itemize}

\subsubsection{Supervisado vs no supervisado}
Supongamos una funci칩n desconocida $y_{\Theta}(\vec{x}) = h_{\Theta}(\vec{x})$, donde x es un ejemplo de entrada y y la salida deseada. En el \textbf{aprendizaje supervisado}, se proporciona un conjunto de pares de entrenamiento (x,y), donde x es la entrada y y es la salida deseada. El objetivo es aprender una funci칩n $h_{\Theta}(\vec{x})$ que mapee las entradas a las salidas. En el \textbf{aprendizaje no supervisado}, solo se proporcionan las entradas x, y el sistema debe encontrar patrones o estructuras en los datos sin conocer las salidas. $\Theta$ hace referencia a los par치metros que tiene el modelo y que hay que entrenar. Por tanto, cuantos menos par치metros haya, m치s r치pido va a ser el modelo.

\subsubsection{Fases de un algoritmo de aprendizaje}
Las fases de un algoritmo de aprendizaje son:
\begin{enumerate}
\item \textbf{Hip칩tesis y datos}: Los datos son representados como vectores\footnote{Aunque no haya una notaci칩n general, vamos a utilizar la negrita no it치lica para denominar que la variable es un vector. }  $\vec{x}_n = (x_{n1} ... x_{nD})^T$, donde D es la dimensi칩n del vector. En el aprendizaje supervisado, tambi칠n se tienen etiquetas $y_n$ que representan la salida deseada. Los datos pueden ser de diferentes tipos: num칠ricos, categ칩ricos, texto, series temporales, etc. La informaci칩n puede estar estructurada (datos gen칠ticos, metereol칩gicos, etc) o no estructurada (im치genes, audio, texto).

\item \textbf{Selecci칩n del modelo}

Se elige un modelo $h_{\Theta}(\vec{x})$ que intenta aproximar la relaci칩n entre las entradas y las salidas. Por ejemplo, si se elige un modelo lineal, $h_{\Theta}(\vec{x}) = a\vec{x} + b$, donde a y b son par치metros que se deben optimizar (correspondientes a $\Theta_1$ y a $\Theta_2$). 

\begin{figure}[h]
\centering
\includegraphics[width = \textwidth]{figs/model-htheta.png}
\end{figure}

La funci칩n de coste $E(y_{\Theta} - y )^2$ mide el error entre la predicci칩n del modelo y la salida real. Este error se divide en un coste reducible que se puede minimizar optimizando los par치metros del modelo, y un coste irreducible que no puede reducirse con los par치metros actuales, requiriendo un cambio en el modelo o la hip칩tesis. La funci칩n del coste se resume en:
$$E(y_{\Theta} - y)^2 = [h_{\Theta}(\vec{x}) - h(\vec{x})]^2 + \epsilon$$

siendo $ [h_{\Theta}(\vec{x}) - h(\vec{x})]^2$ el coste reducible y $\epsilon$ el irreducible. 

\item \textbf{Entrenamiento o aprendizaje}: En esta fase, el modelo se ajusta a los datos de entrenamiento optimizando los par치metros $\Theta$ para minimizar la funci칩n de coste.

Por ejemplo, si tenemos un set de datos logar칤tmico, habr칤a que cambiar de la hip칩tesis de modelo lineal $h_{\Theta}(x) = ax + b$ que solo valdr칤a para una recta, por un modelo polin칩mico $h_{\Theta}(x) = ax^3 + bx^2 + cx + d$ para poder disminuir el error $\epsilon$. El problema es que es muy costoso matem치ticamente cuando aumenta el tama침o de los datos, y puede llevar a un sobreajuste del modelo a los datos de entrenamiento. De una informaci칩n discreta (un set de valores) se busca obtener una soluci칩n continua (la funci칩n). Todo esto no solo permite obtener una aproximaci칩n de los datos intermedios del set de valores dado, si no tambi칠n una predicci칩n de los datos futuros.

Los errores se suelen representar al cuadrado para que no se compensen los errores negativos con los positivos. 

\item \textbf{Testeo o inferencia}: Una vez entrenado, el modelo $h_{\Theta}$ se eval칰a con datos nuevos (no vistos durante el entrenamiento) para ver c칩mo generaliza a situaciones no vistas. As칤, se predice un nuevo $y(\vec{x})$ a un nuevo $\vec{x}$. Esto normalmente se hace separando un set de datos en un set de entrenamiento y un set de evaluaci칩n de forma aleatoria. 

Una vez en este punto, si el error es muy elevado, se vuelve a la selecci칩n del modelo y se establece una nueva hip칩tesis. Esto es un proceso iterativo en el que se eval칰a el rendimiento del sistema hasta que se observe un modelo con un buen ajuste tanto a los valores de entrenamiento como a los valores de test.
\end{enumerate}

\subsection{Tipos de problemas o tareas}
\subsubsection{Aprendizaje supervisado}
\paragraph{Regresi칩n} El objetivo de la regresi칩n es predecir el valor de una variable continua. La salida es un valor num칠rico, y se busca modelar una funci칩n continua que relacione las variables de entrada con la salida. Este proceso implica m칠todos estad칤sticos para estimar las relaciones entre las variables. Por ejemplo, predecir el precio de una casa en funci칩n de su tama침o, ubicaci칩n y otras caracter칤sticas.

\paragraph{Clasificaci칩n} En la clasificaci칩n, el objetivo es asignar una etiqueta categ칩rica a cada instancia de datos. La salida es una etiqueta discreta, como "maligno" o "benigno". El l칤mite de decisi칩n es una hipersuperficie que divide el espacio de caracter칤sticas en regiones, cada una asociada a una clase. Por ejemplo, en la clasificaci칩n de un tumor, se utilizan caracter칤sticas como el tama침o y la tasa de crecimiento para determinar si el tumor es maligno o benigno. Aqu칤, las caracter칤sticas (tama침o y tasa de crecimiento) definen el espacio de entrada, y la etiqueta (maligno/benigno) es la salida binaria.

\subsubsection{Aprendizaje no supervisado}
\paragraph{Clustering} El clustering es una t칠cnica de aprendizaje no supervisado que busca agrupar un conjunto de objetos (o datos) de manera que aquellos que pertenecen al mismo grupo (cl칰ster) sean m치s similares entre s칤 que con los objetos de otros grupos. La similitud se mide utilizando m칠tricas de distancia (como la distancia euclidiana) o similitud, dependiendo del tipo de datos y del algoritmo utilizado. Un ejemplo com칰n es la agrupaci칩n de clientes en segmentos basados en su comportamiento de compra, donde cada cl칰ster representa un grupo de clientes con caracter칤sticas similares.

%04/02 - Aythami
\section{Reducci칩n de dimensionalidad}
La reducci칩n de dimensionalidad es una t칠cnica fundamental en el aprendizaje autom치tico que permite representar datos multidimensionales en un espacio de menor dimensi칩n, preservando la mayor cantidad posible de informaci칩n relevante. Esto es especialmente 칰til para visualizaci칩n, mejora del rendimiento y manejo de la maldici칩n de la dimensionalidad. 
\begin{itemize}
\item \textbf{Visualizaci칩n}: Permite visualizar datos en 2D o 3D, incluso cuando los datos originales tienen muchas m치s dimensiones.
\item \textbf{Mejora del rendimiento}: Reduce el tiempo de entrenamiento y el uso de memoria al trabajar con menos dimensiones. Adem치s, elimina ruido y redundancia en los datos.
\item \textbf{Maldici칩n de la dimensionalidad}: Cuando el n칰mero de dimensiones es muy alto en comparaci칩n con el n칰mero de muestras, los modelos pueden volverse ineficientes o sobreajustarse.
Ejemplo: No tiene sentido ajustar un modelo con 2.000 par치metros si solo se dispone de 10 datos. Los par치metros representan grados de libertad, y en este caso, el modelo no generalizar칤a bien. La reducci칩n de dimensionalidad ayuda a eliminar informaci칩n redundante y mejorar el rendimiento.
\end{itemize}

No obstante, no siempre es necesario o beneficioso reducir la dimensionalidad. Por ejemplo, si las dimensiones originales ya son interpretables y no hay redundancia, o si la p칠rdida de informaci칩n al reducir dimensiones afecta negativamente al modelo.

El objetivo es reducir el n칰mero de variables (dimensiones) en un conjunto de datos, manteniendo la estructura y la informaci칩n m치s importante. La herramienta m치s com칰n es \textbf{PCA (Principal Component Analysis)}, un algoritmo basado en 치lgebra lineal que transforma los datos originales en un nuevo sistema de coordenadas, donde las dimensiones (componentes principales) capturan la mayor varianza posible.

\subsection{Proyecci칩n de datos en dimensiones inferiores}
La idea central de la reducci칩n de dimensionalidad es proyectar datos de un espacio de alta dimensi칩n a uno de menor dimensi칩n, preservando la estructura subyacente.

\paragraph{2D a 1D}
Supongamos que tenemos datos en un espacio bidimensional ($\mathbb{R}^2$). Queremos proyectarlos en una recta unidimensional ($\mathbb{R}$). La recta es una combinaci칩n lineal de las dos dimensiones originales (desde la recta, solo nos podemos mover en una direcci칩n, hacia delante o hacia detr치s), y la proyecci칩n de los datos a esa recta no conlleva p칠rdida de informaci칩n si la recta captura la direcci칩n de m치xima varianza. Matem치ticamente:
$$\vec{x}^{(1)} \in \mathbb{R}^2 \rightarrow z^{(1)} \in \mathbb{R}$$
$$\vec{x}^{(2)} \in \mathbb{R}^2 \rightarrow z^{(2)} \in \mathbb{R}$$
$$\vec{x}^{(N)} \in \mathbb{R}^2 \rightarrow z^{(N)} \in \mathbb{R}$$
El super칤ndice sirve para anotar el dato, y el sub칤ndice para la dimensi칩n.

\begin{figure}[h]
\centering
\includegraphics[width = 0.6\textwidth]{figs/reduccion-dimension-2d.png}
\end{figure}

\paragraph{Extensi칩n a m치s dimensiones}
Esta idea se puede generalizar a espacios de mayor dimensi칩n. Por ejemplo, al pasar de 3D ($\mathbb{R}^3$) a 2D ($\mathbb{R}^2$), se proyectan los datos en un plano bidimensional:
$$\vec{x}^{(i)} \in \mathbb{R}^3 \rightarrow z^{(i)} \in \mathbb{R}^2$$

\subsection{PCA: An치lisis de Componentes Principales}
En el caso de una tabla de expresi칩n g칠nica donde las filas representan pacientes y las columnas corresponden a genes individuales, cada paciente puede describirse como un punto en un espacio de 2000 dimensiones: $\vec{x}^{(i)} \in \mathbb{B}^{2000}$, es decir, un vector de 2000 componentes binarios.

El An치lisis de Componentes Principales (PCA) permite reducir estas 2000 dimensiones a un espacio de menor dimensi칩n, por ejemplo, a dos dimensiones: $\vec{z}^{(i)} \in \mathbb{R}^2$

Sin embargo, al proyectar los datos, el tipo de variable puede cambiar. En este caso, los valores transformados pierden su significado biol칩gico directo (es decir, ya no tienen una interpretaci칩n gen칠tica espec칤fica), pero la proximidad entre puntos en el espacio bidimensional puede interpretarse como una medida de similitud gen칠tica entre sujetos.
\begin{figure}[h]
\centering
\includegraphics[width = 0.7\textwidth]{figs/gene-table1.png}
\includegraphics[width = 0.7\textwidth]{figs/gene-table2.png}
\end{figure}

El algoritmo de PCA busca minimizar el error de proyecci칩n de los datos sobre un subespacio de menor dimensi칩n. Para la reducci칩n de dos dimensiones a una, esto equivale a encontrar un vector $u^{(1)} \in \mathbb{R}^n$ que minimice la distancia entre los puntos originales y sus proyecciones. M치s generalmente, para reducir un espacio de $n$ dimensiones a $k$ dimensiones, PCA busca determinar $k$ vectores ortogonales $u^{(k)}$ que definan el subespacio 칩ptimo para proyectar los datos, minimizando la p칠rdida de informaci칩n: 
$$\vec{x} \in \mathbb{R}^n \rightarrow \vec{z} \in \mathbb{R}^k$$

\begin{figure}[h]
\centering
\includegraphics[width = 0.8\textwidth]{figs/pca-dimensiones.png}
\end{figure}

\subsubsection{Algoritmo de PCA}
